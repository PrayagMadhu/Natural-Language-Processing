{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, Dense, Flatten\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    data=[]\n",
    "    labels=[]\n",
    "    with open(filename, 'r', encoding='latin-1') as f:\n",
    "        temp=f.readlines()\n",
    "        for row in temp:\n",
    "            row_=row.split(':')\n",
    "            row_[1]=row_[1].lower()\n",
    "            data.append(row_[1].strip('\\n').split())\n",
    "            labels.append(row_[0])\n",
    "            \n",
    "    return data, labels\n",
    "\n",
    "train_data, train_labels = read_data(os.getcwd()+'/train_1000.label')\n",
    "test_data, test_labels = read_data(os.getcwd()+'/TREC_10.label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ids={val:i for i,val in enumerate(set(train_labels))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_enc=[label_ids[label] for label in train_labels]\n",
    "test_labels_enc=[label_ids[label] for label in test_labels]\n",
    "train_labels_=tf.one_hot(train_labels_enc, depth=6)\n",
    "test_labels_=tf.one_hot(test_labels_enc, depth=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max=max([len(x) for x in train_data])\n",
    "test_max=max([len(x) for x in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qst in train_data:\n",
    "    for _ in range(train_max-len(qst)):\n",
    "        qst.append('<PAD>')\n",
    "        \n",
    "for qst in test_data:\n",
    "    for _ in range(test_max-len(qst)):\n",
    "        qst.append('<PAD>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_train = np.array(train_data).reshape(-1)\n",
    "flattened_test = np.array(test_data).reshape(-1)\n",
    "flattened=np.append(flattened_train, flattened_test)\n",
    "vocabs=set(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2int={c:i for i, c in enumerate(vocabs)}\n",
    "int2vocab={i:c for i,c in zip(vocab2int.values(), vocab2int.keys())}\n",
    "train_ids=[[vocab2int[word] for word in qst] for qst in train_data]\n",
    "test_ids=[[vocab2int[word] for word in qst] for qst in test_data]\n",
    "train_ids=np.array(train_ids)\n",
    "train_ids=train_ids[:, :, np.newaxis]\n",
    "test_ids=np.array(test_ids)\n",
    "test_ids=test_ids[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids=tf.convert_to_tensor(train_ids, dtype=tf.float32)\n",
    "test_ids=tf.convert_to_tensor(test_ids, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=tf.data.Dataset.from_tensor_slices((train_ids, train_labels_)).shuffle(100).batch(32)\n",
    "test_dataset=tf.data.Dataset.from_tensor_slices((test_ids, test_labels_)).shuffle(100).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 18, 1), (None, 6)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1=Conv1D(32, 3, padding='SAME', activation='relu')\n",
    "        self.conv2=Conv1D(32, 5, padding='SAME', activation='relu')\n",
    "        self.conv3=Conv1D(32, 7, padding='SAME', activation='relu')\n",
    "        self.flatten=Flatten()\n",
    "        self.dense=Dense(num_classes)\n",
    "    \n",
    "    def call(self,x):\n",
    "        l1=self.conv1(x)\n",
    "        l2=self.conv2(x)\n",
    "        l3=self.conv3(x)\n",
    "        l=tf.concat([tf.reduce_max(l1, axis=1), tf.reduce_max(l2, axis=1), tf.reduce_max(l3, axis=1)], axis=1)\n",
    "        l=self.flatten(l)\n",
    "        return self.dense(l)\n",
    "    \n",
    "model=Model(6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object=tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "optm=tf.keras.optimizers.Adam()\n",
    "train_loss=tf.keras.metrics.Mean()\n",
    "train_acc=tf.keras.metrics.CategoricalAccuracy()\n",
    "test_loss=tf.keras.metrics.Mean()\n",
    "test_acc=tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "@tf.function\n",
    "def train_step(data, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions=model(data, training=True)\n",
    "        loss=loss_object(labels, predictions)\n",
    "    gradients=tape.gradient(loss, model.trainable_variables) \n",
    "    optm.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_acc(labels, predictions)\n",
    "    \n",
    "@tf.function\n",
    "def test_step(data, labels):\n",
    "    predictions=model(data)\n",
    "    loss=loss_object(labels, predictions)\n",
    "    \n",
    "    test_loss(loss)\n",
    "    test_acc(labels, predictions)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 13.460238456726074, Accuracy: 49.599998474121094, Test Loss: 18.637968063354492, Test Accuracy: 50.80000305175781\n",
      "Epoch 2, Loss: 12.30281925201416, Accuracy: 54.29999923706055, Test Loss: 21.083158493041992, Test Accuracy: 50.0\n",
      "Epoch 3, Loss: 13.582408905029297, Accuracy: 50.70000457763672, Test Loss: 19.457054138183594, Test Accuracy: 49.20000076293945\n",
      "Epoch 4, Loss: 12.743268966674805, Accuracy: 52.79999923706055, Test Loss: 15.448917388916016, Test Accuracy: 36.0\n",
      "Epoch 5, Loss: 12.718542098999023, Accuracy: 53.10000228881836, Test Loss: 22.753732681274414, Test Accuracy: 47.20000076293945\n",
      "Epoch 6, Loss: 12.501111030578613, Accuracy: 53.29999923706055, Test Loss: 15.297054290771484, Test Accuracy: 53.20000076293945\n",
      "Epoch 7, Loss: 11.791872024536133, Accuracy: 54.900001525878906, Test Loss: 15.758956909179688, Test Accuracy: 52.20000076293945\n",
      "Epoch 8, Loss: 11.320253372192383, Accuracy: 53.79999923706055, Test Loss: 23.80356788635254, Test Accuracy: 51.0\n",
      "Epoch 9, Loss: 13.093412399291992, Accuracy: 49.099998474121094, Test Loss: 17.420915603637695, Test Accuracy: 52.39999771118164\n",
      "Epoch 10, Loss: 11.742602348327637, Accuracy: 56.5, Test Loss: 17.740375518798828, Test Accuracy: 46.79999923706055\n",
      "Epoch 11, Loss: 11.38281536102295, Accuracy: 52.60000228881836, Test Loss: 14.868895530700684, Test Accuracy: 53.79999923706055\n",
      "Epoch 12, Loss: 9.204747200012207, Accuracy: 57.599998474121094, Test Loss: 16.809022903442383, Test Accuracy: 37.599998474121094\n",
      "Epoch 13, Loss: 11.660646438598633, Accuracy: 52.10000228881836, Test Loss: 18.274330139160156, Test Accuracy: 45.400001525878906\n",
      "Epoch 14, Loss: 12.810077667236328, Accuracy: 53.60000228881836, Test Loss: 14.846925735473633, Test Accuracy: 50.400001525878906\n",
      "Epoch 15, Loss: 9.42966079711914, Accuracy: 56.599998474121094, Test Loss: 18.586811065673828, Test Accuracy: 51.400001525878906\n",
      "Epoch 16, Loss: 9.531257629394531, Accuracy: 57.400001525878906, Test Loss: 12.730636596679688, Test Accuracy: 52.39999771118164\n",
      "Epoch 17, Loss: 10.741992950439453, Accuracy: 52.999996185302734, Test Loss: 21.11981201171875, Test Accuracy: 29.0\n",
      "Epoch 18, Loss: 13.581653594970703, Accuracy: 50.19999694824219, Test Loss: 16.326353073120117, Test Accuracy: 35.400001525878906\n",
      "Epoch 19, Loss: 11.647462844848633, Accuracy: 51.89999771118164, Test Loss: 14.255799293518066, Test Accuracy: 52.20000076293945\n",
      "Epoch 20, Loss: 8.620146751403809, Accuracy: 58.499996185302734, Test Loss: 22.97618865966797, Test Accuracy: 28.0\n",
      "Epoch 21, Loss: 11.22375202178955, Accuracy: 52.79999923706055, Test Loss: 18.581653594970703, Test Accuracy: 48.400001525878906\n",
      "Epoch 22, Loss: 10.598043441772461, Accuracy: 54.70000076293945, Test Loss: 19.395082473754883, Test Accuracy: 52.60000228881836\n",
      "Epoch 23, Loss: 8.933710098266602, Accuracy: 58.20000076293945, Test Loss: 18.056289672851562, Test Accuracy: 49.599998474121094\n",
      "Epoch 24, Loss: 13.715368270874023, Accuracy: 48.400001525878906, Test Loss: 14.752155303955078, Test Accuracy: 45.0\n",
      "Epoch 25, Loss: 10.733532905578613, Accuracy: 54.70000076293945, Test Loss: 14.728528022766113, Test Accuracy: 51.0\n",
      "Epoch 26, Loss: 10.317590713500977, Accuracy: 54.400001525878906, Test Loss: 15.282527923583984, Test Accuracy: 39.39999771118164\n",
      "Epoch 27, Loss: 9.665421485900879, Accuracy: 55.29999542236328, Test Loss: 15.415898323059082, Test Accuracy: 32.400001525878906\n",
      "Epoch 28, Loss: 11.745640754699707, Accuracy: 51.89999771118164, Test Loss: 14.544795036315918, Test Accuracy: 48.79999923706055\n",
      "Epoch 29, Loss: 9.366096496582031, Accuracy: 58.20000076293945, Test Loss: 12.216115951538086, Test Accuracy: 49.0\n",
      "Epoch 30, Loss: 9.178313255310059, Accuracy: 57.0, Test Loss: 13.117568016052246, Test Accuracy: 42.599998474121094\n",
      "Epoch 31, Loss: 11.795867919921875, Accuracy: 52.0, Test Loss: 23.270217895507812, Test Accuracy: 43.0\n",
      "Epoch 32, Loss: 10.011109352111816, Accuracy: 55.69999694824219, Test Loss: 12.710271835327148, Test Accuracy: 52.79999923706055\n",
      "Epoch 33, Loss: 8.124242782592773, Accuracy: 58.60000228881836, Test Loss: 18.643882751464844, Test Accuracy: 34.599998474121094\n",
      "Epoch 34, Loss: 8.928104400634766, Accuracy: 56.0, Test Loss: 13.88840389251709, Test Accuracy: 48.79999923706055\n",
      "Epoch 35, Loss: 7.53085994720459, Accuracy: 59.20000076293945, Test Loss: 13.401384353637695, Test Accuracy: 36.79999923706055\n",
      "Epoch 36, Loss: 8.286849021911621, Accuracy: 56.19999694824219, Test Loss: 12.734915733337402, Test Accuracy: 51.79999923706055\n",
      "Epoch 37, Loss: 8.553853988647461, Accuracy: 56.900001525878906, Test Loss: 12.25390625, Test Accuracy: 46.0\n",
      "Epoch 38, Loss: 8.341246604919434, Accuracy: 54.599998474121094, Test Loss: 18.175514221191406, Test Accuracy: 49.599998474121094\n",
      "Epoch 39, Loss: 8.773632049560547, Accuracy: 56.30000305175781, Test Loss: 17.822782516479492, Test Accuracy: 52.39999771118164\n",
      "Epoch 40, Loss: 7.596242904663086, Accuracy: 58.39999771118164, Test Loss: 17.124494552612305, Test Accuracy: 51.0\n",
      "Epoch 41, Loss: 8.304208755493164, Accuracy: 56.30000305175781, Test Loss: 14.832968711853027, Test Accuracy: 46.599998474121094\n",
      "Epoch 42, Loss: 7.818582057952881, Accuracy: 58.099998474121094, Test Loss: 14.53233528137207, Test Accuracy: 48.79999923706055\n",
      "Epoch 43, Loss: 8.145040512084961, Accuracy: 56.400001525878906, Test Loss: 13.351273536682129, Test Accuracy: 52.79999923706055\n",
      "Epoch 44, Loss: 6.505821228027344, Accuracy: 59.79999923706055, Test Loss: 12.43790054321289, Test Accuracy: 53.60000228881836\n",
      "Epoch 45, Loss: 8.554545402526855, Accuracy: 53.20000076293945, Test Loss: 13.089971542358398, Test Accuracy: 51.20000076293945\n",
      "Epoch 46, Loss: 9.25110149383545, Accuracy: 57.099998474121094, Test Loss: 15.736616134643555, Test Accuracy: 47.0\n",
      "Epoch 47, Loss: 9.679098129272461, Accuracy: 52.89999771118164, Test Loss: 13.12366008758545, Test Accuracy: 36.79999923706055\n",
      "Epoch 48, Loss: 8.081071853637695, Accuracy: 58.89999771118164, Test Loss: 13.980598449707031, Test Accuracy: 34.79999923706055\n",
      "Epoch 49, Loss: 9.00007152557373, Accuracy: 55.29999542236328, Test Loss: 15.621048927307129, Test Accuracy: 46.0\n",
      "Epoch 50, Loss: 9.784424781799316, Accuracy: 56.5, Test Loss: 11.89319133758545, Test Accuracy: 54.599998474121094\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (50):\n",
    "    train_loss.reset_states()\n",
    "    train_acc.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_acc.reset_states()\n",
    "    \n",
    "    for img, label in train_dataset:\n",
    "        #print(img.shape)\n",
    "        train_step(img, label)\n",
    "        \n",
    "    for img, label in test_dataset:\n",
    "        test_step(img, label)\n",
    "        \n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print(template.format(epoch+1,\n",
    "                        train_loss.result(),\n",
    "                        train_acc.result()*100,\n",
    "                        test_loss.result(),\n",
    "                        test_acc.result()*100))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
